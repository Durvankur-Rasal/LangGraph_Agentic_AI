{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f64c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c78fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e774e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938e6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSchema(BaseModel):\n",
    "    feedback: str = Field(description=\"Detailed feedback for the essay\")\n",
    "    score : int = Field(description=\"Score out of 10\", ge=0, le=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608069d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e18973",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = \"\"\"India in the Age of AI As the world enters a transformative era defined by artificial intelligence (AI), India stands at a critical juncture — one where it can either emerge as a global leader in AI innovation or risk falling behind in the technology race. The age of AI brings with it immense promise as well as unprecedented challenges, and how India navigates this landscape will shape its socio-economic and geopolitical future.\n",
    "\n",
    "India's strengths in the AI domain are rooted in its vast pool of skilled engineers, a thriving IT industry, and a growing startup ecosystem. With over 5 million STEM graduates annually and a burgeoning base of AI researchers, India possesses the intellectual capital required to build cutting-edge AI systems. Institutions like IITs, IIITs, and IISc have begun fostering AI research, while private players such as TCS, Infosys, and Wipro are integrating AI into their global services. In 2020, the government launched the National AI Strategy (AI for All) with a focus on inclusive growth, aiming to leverage AI in healthcare, agriculture, education, and smart mobility.\n",
    "\n",
    "One of the most promising applications of AI in India lies in agriculture, where predictive analytics can guide farmers on optimal sowing times, weather forecasts, and pest control. In healthcare, AI-powered diagnostics can help address India's doctor-patient ratio crisis, particularly in rural areas. Educational platforms are increasingly using AI to personalize learning paths, while smart governance tools are helping improve public service delivery and fraud detection.\n",
    "\n",
    "However, the path to AI-led growth is riddled with challenges. Chief among them is the digital divide. While metropolitan cities may embrace AI-driven solutions, rural India continues to struggle with basic internet access and digital literacy. The risk of job displacement due to automation also looms large, especially for low-skilled workers. Without effective skilling and re-skilling programs, AI could exacerbate existing socio-economic inequalities.\n",
    "\n",
    "Another pressing concern is data privacy and ethics. As AI systems rely heavily on vast datasets, ensuring that personal data is used transparently and responsibly becomes vital. India is still shaping its data protection laws, and in the absence of a strong regulatory framework, AI systems may risk misuse or bias.\n",
    "\n",
    "To harness AI responsibly, India must adopt a multi-stakeholder approach involving the government, academia, industry, and civil society. Policies should promote open datasets, encourage responsible innovation, and ensure ethical AI practices. There is also a need for international collaboration, particularly with countries leading in AI research, to gain strategic advantage and ensure interoperability in global systems.\n",
    "\n",
    "India's demographic dividend, when paired with responsible AI adoption, can unlock massive economic growth, improve governance, and uplift marginalized communities. But this vision will only materialize if AI is seen not merely as a tool for automation, but as an enabler of human-centered development.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5dd01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The essay is exceptionally well-written and demonstrates a strong command of the English language. The structure is logical, with a clear introduction, well-defined body paragraphs, and a concise conclusion. The arguments flow coherently from one point to the next. Vocabulary is sophisticated and used appropriately (e.g., 'critical juncture', 'burgeoning', 'riddled with challenges', 'exacerbate'). The language is formal and academic in tone, suitable for the subject matter. There are no noticeable grammatical errors or awkward sentence constructions. For an even greater impact, the essay could incorporate slightly more specific, data-driven examples to substantiate some of its claims, but from a language quality perspective, it is excellent.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {essay}'\n",
    "structured_model.invoke(prompt).feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67ed43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPSCState(TypedDict):\n",
    "    essay: str\n",
    "    language_feedback: str\n",
    "    analysis_feedback: str\n",
    "    clarity_feedback: str\n",
    "    overall_feedback: str\n",
    "    individual_scores: Annotated[list[int], operator.add]\n",
    "    avg_score: float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_language(state: UPSCState):\n",
    "    prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "    \n",
    "    return {'language_feedback': output.feedback, 'individual_scores': [output.score]}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_analysis(state: UPSCState):\n",
    "    prompt = f'Evaluate the analysis quality of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "    \n",
    "    return {'analysis_feedback': output.feedback, 'individual_scores': [output.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thought(state: UPSCState):\n",
    "    prompt = f'Evaluate the thought quality of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "    \n",
    "    return {'clarity_feedback': output.feedback, 'individual_scores': [output.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "598b10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(state: UPSCState):\n",
    "\n",
    "    # summary feedback\n",
    "    prompt = f'Based on the following feedbacks create a summarized feedback \\n language feedback - {state[\"language_feedback\"]} \\n depth of analysis feedback - {state[\"analysis_feedback\"]} \\n clarity of thought feedback - {state[\"clarity_feedback\"]}'\n",
    "    overall_feedback = model.invoke(prompt).content\n",
    "\n",
    "    # avg calculate\n",
    "    avg_score = sum(state['individual_scores'])/len(state['individual_scores'])\n",
    "\n",
    "    return {'overall_feedback': overall_feedback, 'avg_score': avg_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c2bec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(UPSCState)\n",
    "\n",
    "graph.add_node('evaluate_language', evaluate_language)\n",
    "graph.add_node('evaluate_analysis', evaluate_analysis)\n",
    "graph.add_node('evaluate_thought', evaluate_thought)\n",
    "graph.add_node('final_evaluation', final_evaluation)\n",
    "\n",
    "# edges\n",
    "graph.add_edge(START, 'evaluate_language')\n",
    "graph.add_edge(START, 'evaluate_analysis')\n",
    "graph.add_edge(START, 'evaluate_thought')\n",
    "\n",
    "graph.add_edge('evaluate_language', 'final_evaluation')\n",
    "graph.add_edge('evaluate_analysis', 'final_evaluation')\n",
    "graph.add_edge('evaluate_thought', 'final_evaluation')\n",
    "\n",
    "graph.add_edge('final_evaluation', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e3373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000013C9EEB7950>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f75fc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay2 = \"\"\"India and AI Time\n",
    "\n",
    "Now world change very fast because new tech call Artificial Intel… something (AI). India also want become big in this AI thing. If work hard, India can go top. But if no careful, India go back.\n",
    "\n",
    "India have many good. We have smart student, many engine-ear, and good IT peoples. Big company like TCS, Infosys, Wipro already use AI. Government also do program “AI for All”. It want AI in farm, doctor place, school and transport.\n",
    "\n",
    "In farm, AI help farmer know when to put seed, when rain come, how stop bug. In health, AI help doctor see sick early. In school, AI help student learn good. Government office use AI to find bad people and work fast.\n",
    "\n",
    "But problem come also. First is many villager no have phone or internet. So AI not help them. Second, many people lose job because AI and machine do work. Poor people get more bad.\n",
    "\n",
    "One more big problem is privacy. AI need big big data. Who take care? India still make data rule. If no strong rule, AI do bad.\n",
    "\n",
    "India must all people together – govern, school, company and normal people. We teach AI and make sure AI not bad. Also talk to other country and learn from them.\n",
    "\n",
    "If India use AI good way, we become strong, help poor and make better life. But if only rich use AI, and poor no get, then big bad thing happen.\n",
    "\n",
    "So, in short, AI time in India have many hope and many danger. We must go right road. AI must help all people, not only some. Then India grow big and world say \"good job India\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7665bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 24.333021501s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 22.114323237s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 22.114323237s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 17.926857971s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 17\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 17.926857971s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 17\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 9.731383861s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 9\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 9.731383861s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 9\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m intial_state = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33messay\u001b[39m\u001b[33m'\u001b[39m: essay2\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintial_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2657\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2655\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2656\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2657\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2658\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2662\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2663\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2664\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2666\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2667\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mfinal_evaluation\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfinal_evaluation\u001b[39m(state: UPSCState):\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# summary feedback\u001b[39;00m\n\u001b[32m      4\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBased on the following feedbacks create a summarized feedback \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m language feedback - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m\"\u001b[39m\u001b[33mlanguage_feedback\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m depth of analysis feedback - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m\"\u001b[39m\u001b[33manalysis_feedback\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m clarity of thought feedback - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m\"\u001b[39m\u001b[33mclarity_feedback\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     overall_feedback = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m.content\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# avg calculate\u001b[39;00m\n\u001b[32m      8\u001b[39m     avg_score = \u001b[38;5;28msum\u001b[39m(state[\u001b[33m'\u001b[39m\u001b[33mindividual_scores\u001b[39m\u001b[33m'\u001b[39m])/\u001b[38;5;28mlen\u001b[39m(state[\u001b[33m'\u001b[39m\u001b[33mindividual_scores\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1676\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1673\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1676\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     **kwargs: Any,\n\u001b[32m   1023\u001b[39m ) -> LLMResult:\n\u001b[32m   1024\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1790\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:238\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    231\u001b[39m params = (\n\u001b[32m    232\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Users\\Public\\Anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Users\\Public\\Anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:208\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlocation is not supported\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc.message:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:869\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    868\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:75\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\grpc\\_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\grpc\\_interceptor.py:329\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:78\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     80\u001b[39m     response_metadata = response.trailing_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\grpc\\_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    306\u001b[39m (\n\u001b[32m    307\u001b[39m     new_method,\n\u001b[32m    308\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     new_compression,\n\u001b[32m    313\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\grpc\\_channel.py:1192\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1185\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1190\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1191\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Langgraph\\myenv\\Lib\\site-packages\\grpc\\_channel.py:1165\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1148\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1149\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1150\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1163\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1164\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1165\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1166\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "intial_state = {\n",
    "    'essay': essay2\n",
    "}\n",
    "\n",
    "workflow.invoke(intial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66f139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
